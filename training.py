import pandas as pd
import nltk
import re
import joblib
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from sklearn.pipeline import Pipeline

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª NLTK Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass

class ArabicViolenceClassifier:
    def __init__(self):
        self.pipeline = None

    def preprocess_arabic_text(self, text):
        if pd.isna(text):
            return ""
        text = str(text)
        text = re.sub(r'[a-zA-Z0-9]', '', text)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\u0600-\u06FF\s]', '', text)
        return text.strip()

    def load_dataset(self, file_path):
        try:
            df = pd.read_excel(file_path)
            if 'comment' not in df.columns or 'label' not in df.columns:
                print("Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø©: comment Ùˆ label")
                return None, None
            df['processed_text'] = df['comment'].apply(self.preprocess_arabic_text)
            df = df[df['processed_text'].str.len() > 0]
            return df['processed_text'].tolist(), df['label'].tolist()
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
            return None, None

    def train_model(self, texts, labels, model_type='svm'):
        X_train, X_test, y_train, y_test = train_test_split(
            texts, labels, test_size=0.2, random_state=42, stratify=labels
        )

        if model_type == 'nb':
            classifier = MultinomialNB()
        elif model_type == 'svm':
            classifier = SVC(kernel='linear', probability=True)
        else:
            classifier = MultinomialNB()

        self.pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
            ('clf', classifier)
        ])

        print(f"Training model: {model_type}")
        self.pipeline.fit(X_train, y_train)
        y_pred = self.pipeline.predict(X_test)
        print(f"\nâœ… Accuracy: {accuracy_score(y_test, y_pred):.2f}")
        print("\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['Non-Bullying', 'Bullying']))

    def predict_text(self, text):
        processed = self.preprocess_arabic_text(text)
        pred = self.pipeline.predict([processed])[0]
        prob = self.pipeline.predict_proba([processed])[0]
        return {
            "prediction": "Bullying" if pred == 1 else "Non-Bullying",
            "confidence": max(prob)
        }

def main():
    classifier = ArabicViolenceClassifier()
    print("=== Arabic Violence Detection System ===")
    print("1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
    texts, labels = classifier.load_dataset("fake_comments_dataset.xlsx")

    if texts is None or labels is None:
        print("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ù„Ù.")
        return

    classifier.train_model(texts, labels, model_type='svm')

    while True:
        user_input = input("\nğŸ“ Ø£Ø¯Ø®Ù„ ØªØ¹Ù„ÙŠÙ‚ Ù„Ù„ØªØ¬Ø±Ø¨Ø© (Ø£Ùˆ 'quit' Ù„Ù„Ø®Ø±ÙˆØ¬): ").strip()
        if user_input.lower() == 'quit':
            break
        result = classifier.predict_text(user_input)
        print(f"ğŸ” Ø§Ù„ØªØµÙ†ÙŠÙ: {result['prediction']}, Ø§Ù„Ø«Ù‚Ø©: {result['confidence']:.2f}")

if __name__ == "__main__":
    main()
