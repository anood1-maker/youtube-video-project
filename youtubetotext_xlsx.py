
import yt_dlp
import speech_recognition as sr
from pydub import AudioSegment
import pandas as pd
import os
import tempfile
from googleapiclient.discovery import build
import re

class YouTubeArabicProcessor:
    def __init__(self, youtube_api_key=None):
        self.youtube_api_key = youtube_api_key
        self.recognizer = sr.Recognizer()

    def clean_filename(self, name):
        invalid = r'\/:*?"<>|ï½œ'
        return ''.join(c for c in name if c not in invalid)

    def extract_video_id(self, url):
        video_id_match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11})', url)
        if video_id_match:
            return video_id_match.group(1)
        return None

    def download_audio(self, youtube_url, output_path):
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'wav',
                'preferredquality': '192',
            }],
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            raw_title = info.get('title', 'Unknown')
            clean_title = self.clean_filename(raw_title)

            # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ Ù…Ù„Ù .wav ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙˆØ£Ø¹Ø¯ ØªØ³Ù…ÙŠØªÙ‡
            for filename in os.listdir(output_path):
                if filename.lower().endswith(".wav"):
                    original_path = os.path.join(output_path, filename)
                    new_path = os.path.join(output_path, f"{clean_title}.wav")
                    os.rename(original_path, new_path)
                    return new_path, clean_title

            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ø¨ØµÙŠØºØ© WAV.")
            return None, clean_title

    def transcribe_audio_chunks(self, audio_file, chunk_duration=30):
        audio = AudioSegment.from_wav(audio_file)
        chunks = []
        chunk_length_ms = chunk_duration * 1000
        for i in range(0, len(audio), chunk_length_ms):
            chunk = audio[i:i + chunk_length_ms]
            chunks.append(chunk)

        transcriptions = []
        for i, chunk in enumerate(chunks):
            try:
                temp_path = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
                chunk.export(temp_path, format="wav")
                with sr.AudioFile(temp_path) as source:
                    audio_data = self.recognizer.record(source)
                    try:
                        text = self.recognizer.recognize_google(audio_data, language='ar-SA')
                        start_time = i * chunk_duration
                        end_time = min((i + 1) * chunk_duration, len(audio) / 1000)
                        transcriptions.append({
                            'start_time': start_time,
                            'end_time': end_time,
                            'text': text
                        })
                        print(f"âœ… ØªÙ… ØªÙØ±ÙŠØº Ø§Ù„Ù…Ù‚Ø·Ø¹ {i+1} Ø¨Ù†Ø¬Ø§Ø­")
                    except sr.UnknownValueError:
                        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… ÙÙ‡Ù… Ø§Ù„ØµÙˆØª ÙÙŠ Ø§Ù„Ù…Ù‚Ø·Ø¹ {i+1}")
                    except sr.RequestError as e:
                        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª: {e}")
                os.unlink(temp_path)
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø·Ø¹ {i+1}: {e}")
        return transcriptions

    def get_video_comments(self, video_id, max_results=100):
        if not self.youtube_api_key:
            print("âŒ Ù„Ù… ÙŠØªÙ… ØªÙˆÙÙŠØ± Ù…ÙØªØ§Ø­ YouTube API")
            return []
        try:
            youtube = build('youtube', 'v3', developerKey=self.youtube_api_key)
            comments = []
            next_page_token = None
            while len(comments) < max_results:
                request = youtube.commentThreads().list(
                    part='snippet',
                    videoId=video_id,
                    maxResults=min(100, max_results - len(comments)),
                    pageToken=next_page_token,
                    order='relevance'
                )
                response = request.execute()
                for item in response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comments.append({
                        'author': comment['authorDisplayName'],
                        'comment': comment['textOriginal'],
                        'likes': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    })
                next_page_token = response.get('nextPageToken')
                if not next_page_token:
                    break
            return comments
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª: {e}")
            return []

    def save_to_excel(self, data, filename, columns):
        df = pd.DataFrame(data)
        if not df.empty and columns:
            df = df[columns]
        df.to_excel(filename, index=False)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {filename}")

    def process_video(self, youtube_url, output_dir="output"):
        os.makedirs(output_dir, exist_ok=True)
        video_id = self.extract_video_id(youtube_url)
        if not video_id:
            print("âŒ Ø±Ø§Ø¨Ø· ÙŠÙˆØªÙŠÙˆØ¨ ØºÙŠØ± ØµØ§Ù„Ø­")
            return
        print(f"ğŸ¬ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ID: {video_id}")
        try:
            print("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª...")
            audio_file, title = self.download_audio(youtube_url, output_dir)
            if audio_file is None:
                print("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­.")
                return

            print(f"ğŸµ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª: {title}")

            print("ğŸ“ ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (Ø¹Ø±Ø¨ÙŠ)...")
            transcriptions = self.transcribe_audio_chunks(audio_file)
            transcription_filename = os.path.join(output_dir, f"{title}_transcription.xlsx")
            self.save_to_excel(transcriptions, transcription_filename, ['start_time', 'end_time', 'text'])

            print("ğŸ’¬ Ø¬Ù„Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª...")
            comments = self.get_video_comments(video_id)
            comments_filename = os.path.join(output_dir, f"{title}_comments.xlsx")
            self.save_to_excel(comments, comments_filename, ['author', 'comment', 'likes', 'published_at'])

            if os.path.exists(audio_file):
                os.remove(audio_file)
            print("âœ… ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")

def main():
    youtube_api_key = "AIzaSyDS9f46i4aKcqUL90cWMNSu5e5ung4BErc"
    youtube_url = "https://www.youtube.com/watch?v=g8w-XMxsLP8"
    processor = YouTubeArabicProcessor(youtube_api_key)
    processor.process_video(youtube_url)

if __name__ == "__main__":
    main()
